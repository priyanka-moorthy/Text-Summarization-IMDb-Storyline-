{"cells":[{"cell_type":"markdown","source":["Install and load the required packages"],"metadata":{"id":"D4qudYKLgUyP"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"WD_vnyLXZQzD"},"outputs":[],"source":["!pip install transformers -q\n","!pip install wandb -q\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pzM1_ykHaFur"},"outputs":[],"source":["\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n","\n","# Importing the T5 modules from huggingface/transformers\n","from transformers import T5Tokenizer, T5ForConditionalGeneration #t5 model from huggingface\n","\n","import wandb #weights and biases library"]},{"cell_type":"markdown","source":["Check if we have GPU access"],"metadata":{"id":"u1djMOwggqS9"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KvPxXdKJguYB","outputId":"f5bd3750-1bdf-4c91-e224-8f4617458c0a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Dec  5 07:23:34 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   45C    P0    26W /  70W |      3MiB / 15109MiB |      4%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["\n","!nvidia-smi"]},{"cell_type":"markdown","source":["setting device for gpu use"],"metadata":{"id":"6Y51S0gkg0yF"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"NLxxwd1scQNv"},"outputs":[],"source":["\n","from torch import cuda\n","device = 'cuda' if cuda.is_available() else 'cpu'\n","\n"]},{"cell_type":"markdown","source":["login to weights and biases "],"metadata":{"id":"Y0kZ1DCJg42H"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L-ePh9dEKXMw","outputId":"d9d075f1-569e-4b42-b73e-9ed69ef7d624"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msnekkanti\u001b[0m (\u001b[33mnlp_sachin\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]}],"source":["\n","!wandb login"]},{"cell_type":"markdown","source":["Creating a custom dataset for reading the dataframe and loading it into the dataloader to pass it to the neural network at a later stage for finetuning the model and to prepare it for predictions"],"metadata":{"id":"UD_JuUkBg_oK"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"932p8NhxeNw4"},"outputs":[],"source":["\n","\n","class CustomDataset(Dataset):\n","\n","    def __init__(self, dataframe, tokenizer, source_len, summ_len):\n","        self.tokenizer = tokenizer\n","        self.data = dataframe\n","        self.source_len = source_len\n","        self.summ_len = summ_len\n","        self.text = self.data.text\n","        self.ctext = self.data.ctext\n","\n","    def __len__(self):\n","        return len(self.text)\n","\n","    def __getitem__(self, index):\n","        ctext = str(self.ctext[index])\n","        ctext = ' '.join(ctext.split())\n","\n","        text = str(self.text[index])\n","        text = ' '.join(text.split())\n","\n","        source = self.tokenizer.batch_encode_plus([ctext], max_length= self.source_len, pad_to_max_length=True,return_tensors='pt')\n","        target = self.tokenizer.batch_encode_plus([text], max_length= self.summ_len, pad_to_max_length=True,return_tensors='pt')\n","\n","        source_ids = source['input_ids'].squeeze()\n","        source_mask = source['attention_mask'].squeeze()\n","        target_ids = target['input_ids'].squeeze()\n","        target_mask = target['attention_mask'].squeeze()\n","\n","        return {\n","            'source_ids': source_ids.to(dtype=torch.long), \n","            'source_mask': source_mask.to(dtype=torch.long), \n","            'target_ids': target_ids.to(dtype=torch.long),\n","            'target_ids_y': target_ids.to(dtype=torch.long)\n","        }"]},{"cell_type":"markdown","source":["Creating the training function"],"metadata":{"id":"aYpqoEEEhVnB"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"SaPAR7TWmxoM"},"outputs":[],"source":["\n","\n","def train(epoch, tokenizer, model, device, loader, optimizer):\n","    model.train()\n","    for _,data in enumerate(loader, 0):\n","        y = data['target_ids'].to(device, dtype = torch.long)\n","        y_ids = y[:, :-1].contiguous()\n","        lm_labels = y[:, 1:].clone().detach()\n","        lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n","        ids = data['source_ids'].to(device, dtype = torch.long)\n","        mask = data['source_mask'].to(device, dtype = torch.long)\n","\n","        outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, labels=lm_labels)\n","        loss = outputs[0]\n","        \n","        if _%10 == 0:\n","            wandb.log({\"Training Loss\": loss.item()})\n","\n","        if _%500==0:\n","            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n","        \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        # xm.optimizer_step(optimizer)\n","        # xm.mark_step()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j9TNdHlQ0CLz"},"outputs":[],"source":["def validate(epoch, tokenizer, model, device, loader):\n","    model.eval()\n","    predictions = []\n","    actuals = []\n","    with torch.no_grad():\n","        for _, data in enumerate(loader, 0):\n","            y = data['target_ids'].to(device, dtype = torch.long)\n","            ids = data['source_ids'].to(device, dtype = torch.long)\n","            mask = data['source_mask'].to(device, dtype = torch.long)\n","\n","            generated_ids = model.generate(\n","                input_ids = ids,\n","                attention_mask = mask, \n","                max_length=150, \n","                num_beams=2,\n","                repetition_penalty=2.5, \n","                length_penalty=1.0, \n","                early_stopping=True\n","                )\n","            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n","            target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n","            if _%100==0:\n","                print(f'Completed {_}')\n","\n","            predictions.extend(preds)\n","            actuals.extend(target)\n","    return predictions, actuals"]},{"cell_type":"code","source":["pip install sentencepiece==0.1.91\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":260},"id":"F7i3bqIhCunZ","outputId":"d9ae7148-ba46-4706-9f0b-326f66ca5f31"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece==0.1.91\n","  Using cached sentencepiece-0.1.91-cp38-cp38-manylinux1_x86_64.whl (1.1 MB)\n","Installing collected packages: sentencepiece\n","  Attempting uninstall: sentencepiece\n","    Found existing installation: sentencepiece 0.1.94\n","    Uninstalling sentencepiece-0.1.94:\n","      Successfully uninstalled sentencepiece-0.1.94\n","Successfully installed sentencepiece-0.1.91\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["sentencepiece"]}}},"metadata":{}}]},{"cell_type":"markdown","source":["defining key variables "],"metadata":{"id":"l9s_k5PDhmMy"}},{"cell_type":"code","source":["\n","\n","wandb.init(project=\"transformers_tutorials_summarization\")\n","\n"," \n","config = wandb.config          # Initialize config\n","config.TRAIN_BATCH_SIZE = 2    # input batch size for training (default: 64)\n","config.VALID_BATCH_SIZE = 2    # input batch size for testing (default: 1000)\n","config.TRAIN_EPOCHS = 2        # number of epochs to train (default: 10)\n","config.VAL_EPOCHS = 1 \n","config.LEARNING_RATE = 1e-4    # learning rate (default: 0.01)\n","config.SEED = 42               # random seed (default: 42)\n","config.MAX_LEN = 512\n","config.SUMMARY_LEN = 250 \n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":307},"id":"N9NThPcYOtR8","outputId":"1a290bb9-ad12-4966-faf3-62d6bd0e8f8c"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Finishing last run (ID:2eww1y3s) before initializing another..."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training Loss</td><td>█▄▄▄▃▃▃▄▁▃▃▂▂▃▂▃▂▃▂▂▂▃▃▂▂▁▃▂▂▂▂▁▂▂▂▂▁▃▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training Loss</td><td>4.96108</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Synced <strong style=\"color:#cdcd00\">comfy-bee-13</strong>: <a href=\"https://wandb.ai/nlp_sachin/transformers_tutorials_summarization/runs/2eww1y3s\" target=\"_blank\">https://wandb.ai/nlp_sachin/transformers_tutorials_summarization/runs/2eww1y3s</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20221205_073114-2eww1y3s/logs</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Successfully finished last run (ID:2eww1y3s). Initializing new run:<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.13.5"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20221205_074735-2br2l1sg</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/nlp_sachin/transformers_tutorials_summarization/runs/2br2l1sg\" target=\"_blank\">honest-pyramid-14</a></strong> to <a href=\"https://wandb.ai/nlp_sachin/transformers_tutorials_summarization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}}]},{"cell_type":"code","source":["\n","torch.manual_seed(config.SEED) # pytorch random seed\n","np.random.seed(config.SEED) # numpy random seed\n","torch.backends.cudnn.deterministic = True\n","\n","\n","tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")# tokenizer\n","\n","\n","\n"],"metadata":{"id":"v9PrMLtZO-U8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["importing the custom dataset in csv format"],"metadata":{"id":"vVRSgfuQiFIs"}},{"cell_type":"code","source":[" \n","\n","df = pd.read_csv('imdb.csv',encoding='latin-1')\n","df = df[['text','ctext']]\n","df.ctext = 'summarize: ' + df.ctext # Adding the summarzie text in front of the text. This is to format the dataset similar to how T5 model was trained for summarization task. \n","print(df.head())\n","\n","\n"],"metadata":{"id":"T1b0YClhOtVy","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2ea632bc-12de-4b6f-8d6b-3c4ec484a65a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                text  \\\n","0  chronicl experi formerli success banker prison...   \n","1  godfath vito corleon head corleon mafia famili...   \n","2  jule winnfield vincent vega two hit men retrie...   \n","3  continu saga corleon crime famili tell stori y...   \n","4  dom cobb skill thief absolut best danger art e...   \n","\n","                                               ctext  \n","0  summarize: two imprison men bond number year f...  \n","1  summarize: age patriarch organ crime dynasti p...  \n","2  summarize: live two mob hitmen boxer gangster ...  \n","3  summarize: earli life career vito corleon new ...  \n","4  summarize: thief steal corpor secret use dream...  \n"]}]},{"cell_type":"markdown","source":["dataset creation and dataloding"],"metadata":{"id":"BsmtjpGyicIn"}},{"cell_type":"code","source":[" \n","train_size = 0.8\n","train_dataset=df.sample(frac=train_size,random_state = config.SEED)\n","val_dataset=df.drop(train_dataset.index).reset_index(drop=True)\n","train_dataset = train_dataset.reset_index(drop=True)\n","\n","print(\"FULL Dataset: {}\".format(df.shape))\n","print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n","print(\"TEST Dataset: {}\".format(val_dataset.shape))\n","\n","\n","# splitting the dataset\n","training_set = CustomDataset(train_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n","val_set = CustomDataset(val_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-a3EydriPpcf","outputId":"aecce656-f2fd-4b67-b4dc-84bea9bc9374"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["FULL Dataset: (787, 2)\n","TRAIN Dataset: (630, 2)\n","TEST Dataset: (157, 2)\n"]}]},{"cell_type":"markdown","source":["parameters for dataloaders"],"metadata":{"id":"VT8Qcjfnimz-"}},{"cell_type":"code","source":["\n","train_params = {\n","    'batch_size': config.TRAIN_BATCH_SIZE,\n","    'shuffle': True,\n","    'num_workers': 0\n","    }\n","\n","val_params = {\n","    'batch_size': config.VALID_BATCH_SIZE,\n","    'shuffle': False,\n","    'num_workers': 0\n","    }\n","\n","# Creation of Dataloaders for testing and validation\n","training_loader = DataLoader(training_set, **train_params)\n","val_loader = DataLoader(val_set, **val_params)\n","\n","\n","\n"],"metadata":{"id":"E91DLSSOPpf7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"EvSh-Q5BOtbE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Defining the model"],"metadata":{"id":"ziUcp2h8itFY"}},{"cell_type":"code","source":["# Defining the model. We are using t5-base model and added a Language model layer on top for generation of Summary. \n","# Further this model is sent to device (GPU/TPU) for using the hardware.\n","model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n","model = model.to(device)\n","\n"],"metadata":{"id":"RxVYvZT3PpjX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Defining the optimizer that will be used to tune the weights of the network in the training session. \n","optimizer = torch.optim.Adam(params =  model.parameters(), lr=config.LEARNING_RATE)\n","\n"],"metadata":{"id":"dUBU-RgzP97c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Log metrics with wandb\n","wandb.watch(model, log=\"all\")\n","# Training loop\n","print('Initiating Fine-Tuning for the model on our dataset')\n","\n","for epoch in range(config.TRAIN_EPOCHS):\n","    train(epoch, tokenizer, model, device, training_loader, optimizer)\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JbcF28PSQDNU","outputId":"6aa8a47e-a9b4-4d40-8ac2-7b34cb974436"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["Initiating Fine-Tuning for the model on our dataset\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:1938: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss:  9.81059455871582\n","Epoch: 1, Loss:  4.9565863609313965\n"]}]},{"cell_type":"markdown","source":["Saving the predictions to csv file"],"metadata":{"id":"SJHIjRqpi2Ei"}},{"cell_type":"code","source":["\n","print('Now generating summaries on our fine tuned model for the validation dataset and saving it in a dataframe')\n","for epoch in range(config.VAL_EPOCHS):\n","    predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\n","    final_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})\n","    final_df.to_csv('predictions.csv')\n","    print('Output Files generated for review')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dhBZy9UUQDQi","outputId":"9dd961c5-8adc-47bd-a781-513a5d6bce40"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Now generating summaries on our fine tuned model for the validation dataset and saving it in a dataframe\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py:760: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  beam_id = beam_token_id // vocab_size\n"]},{"output_type":"stream","name":"stdout","text":["Completed 0\n","Output Files generated for review\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"URp0Yom-QDTn"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"nbformat":4,"nbformat_minor":0}